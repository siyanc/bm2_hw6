---
title: "DS2_HW4_REGRESSION_TREE"
author: "Siyan Chen"
date: "4/21/2019"
output: pdf_document
---

```{r setup, include=FALSE}
library(lasso2)
library(mgcv)
library(ISLR)
library(dplyr)
library(ranger)
library(caret)
library(rpart) # classification tree
library(rpart.plot)
library(gbm)
library(randomForest)
```

```{r}
data(Prostate)
head(Prostate)

set.seed(1)
rowtrain = createDataPartition(y = Prostate$lpsa,
                              p = 0.75,
                              list = FALSE)
ctr1 = trainControl(method = "cv")

```

### 1a) Fit a regression tree withlpsaas the response;Use cross-validation to determine the optimal tree size. Which tree size correspondsto the lowest cross-validation error?  Is this the same as the tree size obtained usingthe 1 SE rule?



```{r}
set.seed(1)
rpart.fit = train(lpsa~., Prostate,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-6,-2,length=20))), trControl = ctr1)
rpart.plot(rpart.fit$finalModel)

#####
set.seed(1) 
tree1 = rpart(formula = lpsa~., data = Prostate)
rpart.plot(tree1)
cp_table = printcp(tree1)### cross validation built in rpart; large cp give smaller tree
plotcp(tree1)
### tree by minimium cross validation error
minerror = which.min(cp_table[,4])
tree2 = prune(tree1, cp = cp_table[minerror,1])
### 1SE rule- simplest model with error smaller than the line
tree3 = prune(tree1, cp = cp_table[cp_table[,4]<cp_table[minerror,4]+cp_table[minerror,5],1][1])
# split 3
rpart.plot(tree3)
```

According to the plot. the optimal tree size is 7+1 = 8 by cross validation. According to 1SE rule, the optimal split is 3. Therefore, the tree size are different. 

### 2  Create  a  plot  of  the  final  tree  you  choose.   Pick  one  of  the  terminal  nodes,  andinterpret the information displayed.

```{r}
rpart.plot(tree3)
```

Since both models have similar cross validation error. We should choose the simpler model which is 1 SE model. 
Node 3.8 interpretation: when the log cancer volumn is greater 2.5. the log mean of log prostate specific antigen is 3.8. The nodes include 22% response of training dataset.

### (c)  Perform bagging and report the variable importance.

```{r}
set.seed(2)
rf.grid = expand.grid(mtry = 8,
                      splitrule = "variance",
                     min.node.size = 10:30)
bagging.fit = train(lpsa~., Prostate, 
                    method = "ranger",
                    tuneGrid = rf.grid,
                    trControl = ctr1)
ggplot(bagging.fit , highlight = TRUE)

bagging.imp = ranger(lpsa~., Prostate,
                  mtry = 8, 
                  splitrule = "variance", 
                  min.node.size = 11,
                  importance = "permutation",
                  scale.permutation.importance = TRUE)
barplot(sort(ranger::importance(bagging.imp), decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7, col = colorRampPalette(colors = c("darkred", "white", "darkblue"))(19))
                  
```

Based on the plot above, the variable importance is lcavol > lweight > svi > pgg45 > lcp > gleason > lbph > age.


### (d)  Perform random forests and report the variable importance.

```{r}
### tuning parameter
rf.grid = expand.grid(mtry = 1:6,
                      splitrule = "variance",
                      min.node.size = 10:30)### ?
### fit model
set.seed(3)
rf.fit = train(lpsa~., Prostate, 
               method = "ranger",
               tuneGrid = rf.grid,
               trControl = ctr1)
### tuning parameter choosen
ggplot(rf.fit, highlight = TRUE)
### variable importance.
rf.final.imp = ranger(lpsa~., Prostate,
                      mtry = 4, splitrule = "variance",
                      min.node.size = 24,
                      importance = "permutation",
                      scale.permutation.importance = TRUE)
barplot(sort(ranger::importance(rf.final.imp), decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7, col = colorRampPalette(colors = c("darkred", "white", "darkblue"))(19))
```

Based on the plot above, the variable importance is lcavol > lweight > svi > lcp > pgg45 > gleason > lbph > age.

### (e)  Perform boosting and report the variable importance.

```{r}
### tuning parameter
gbm.grid = expand.grid(n.trees = c(2000,3000),  
                       interaction.depth = 2:10,
                       shrinkage = c(0.001, 0.003, 0.005),
                       n.minobsinnode = 1)
### fit model
gbm.fit = train(lpsa~.,Prostate,
                method = "gbm",
                tuneGrid = gbm.grid,
                trControl = ctr1,
                verbose = FALSE)
ggplot(gbm.fit, highlight = TRUE)
summary(gbm.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```
Based on the plot above, the variable importance is lcavol > lweight > lcp > age > svi  > pgg45 > lbph > gleason

### (f)  Which of the above models will you select to predict PSA level?  Explain

```{r}
resamp = resamples(list(rpart = rpart.fit, bagging = bagging.fit, rf = rf.fit, gbm = gbm.fit))
summary(resamp)
```
Boosting model is selected because the cross validation error of boosting model is smallest among these models. 

# Problem 2

```{r}
data(OJ)
levels(OJ$Purchase)
rowtrain2 = createDataPartition(y = OJ$Purchase,
                                p = 800/1070,
                                list = FALSE)

```


### (a)  Fit a classification tree to the training set, withPurchaseas the response and theother  variables  as  predictors.   Use  cross-validation  to  determine  the  tree  size  andcreate a plot of the final tree.  Predict the response on the test data.  What is the testclassification error rate?

```{r}
ctr1 = trainControl(method = "repeatedcv",
                    summaryFunction = twoClassSummary,
                    classProbs = TRUE)
set.seed(1)
rpart.fit2 = train(Purchase~.,OJ,
                  subset = rowtrain2,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-6,-3,len=20))),
                  trControl = ctr1,
                  metric = "ROC")
ggplot(rpart.fit2, highlight = TRUE)
rpart.fit2$finalModel$cptable
### plot of final tree
rpart.plot(rpart.fit2$finalModel)
### predict
pred = predict(rpart.fit2, newdata = OJ[-rowtrain2,])
### test classification error rate  
mean(pred != OJ[-rowtrain2,]$Purchase)
```

According to cross validation, the number of split is 10 and the optimal tree size is 11.The test classification error rate is 0.1858736.

### (b)  Perform random forests on the training set and report variable importance.  What isthe test error rate?

```{r}
rf.grid2 = expand.grid(mtry = 8:14,
                      splitrule = "gini",
                      min.node.size = seq(30,60,length = 5))
set.seed(1)
rf.fit2 = train(Purchase~., OJ,
                subset = rowtrain2,
                method = "ranger",
                tuneGrid =  rf.grid2,
                metric = "ROC",
                trControl = ctr1)

ggplot(rf.fit2, highlight = TRUE)

### VARIABLE IMPORTANCE
rf2.final.imp = ranger(Purchase~., OJ[rowtrain2,],
                       mtry = 9 ,
                       min.node.size = 45,
                        splitrule = "gini",
                       importance = "permutation",
                       scale.permutation.importance = TRUE)
barplot(sort(ranger::importance(rf2.final.imp), decreasing = FALSE),
        las = 2, hori = TRUE, cex.names = 0.7,
        col = colorRampPalette(colors = c("cyan","blue"))(8))
### test error rate

pred_rf = predict(rf.fit2, newdata = OJ[-rowtrain2,])
mean(pred_rf!= OJ[-rowtrain2,]$Purchase)

```
The importance of variable was shown above.

The test classification error rate is 0.1821561.

### (c)  Perform boosting on the training set and report variable importance.  What is thetest error rate?

```{r}
gbm2.grid = expand.grid(n.trees = c(2000, 3000, 4000),
                        interaction.depth = 1:6,
                        shrinkage = c(0.001,0.003,0.005),
                        n.minobsinnode = 1)
gbm2.fit = train(Purchase~., OJ[rowtrain2,],
                 tuneGrid = gbm2.grid,
                 trControl = ctr1,
                 method = "gbm",
                 distribution = "bernoulli",
                 metric = "ROC",
                 verbose = FALSE)
ggplot(gbm2.fit, highligh = TRUE)
### important variable
summary(gbm2.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
### test error rate
pred_gbm2 = predict(gbm2.fit, newdata = OJ[-rowtrain2,])
mean(pred_gbm2!=OJ[-rowtrain2,]$Purchase)
              
```
The importance of variable was shown above.
The test classification error rate is 0.1747212.
